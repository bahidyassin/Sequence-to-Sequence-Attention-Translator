# Sequence to Sequence Attention Translator:
##### Yassin Bahid


## Introduction:

In the search for a good neural network translator, we study the Sequence 2 sequence model presented in sutskever's paper: https://arxiv.org/abs/1409.3215. we follow the implementation in: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html. We choose the implementation using the attention decoder where the context vector of the sequences is taken in consideration in the decoding.
